{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3:  Reddit API Classification & Natural Language Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. API Web Scraping & Data Cleaning - /r/bigdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [1.Data Scraping](#1.Data-Scraping)<br>\n",
    "- [2.Import Data and Data Cleaning](#2.Import-Data-and-Data-Cleaning)<br>\n",
    "- [3.Data Frame Export](#3.Data-Frame-Export)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from xml.sax.saxutils import unescape\n",
    "\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.reddit.com/r/bigdata.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/bigdata.json\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gis3xu\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gg651b\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_geuszg\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gd4jpo\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gad0ah\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g7moca\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g469ow\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g1vppx\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fz4oke\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fw43h8\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ftk2ap\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_frj7h1\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fnrsvr\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fl4rnw\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fi20py\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fg471r\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fdquhb\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fcanxx\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f9fqm1\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f6znd5\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f4rwrv\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f1o83o\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_eycuyz\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_euwtm6\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ese859\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_eo6sf5\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_elb9sv\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ehiufb\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ed74xx\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ebsba1\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e9jcd0\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e6lxnk\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e2fskv\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dzutvv\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dw9or8\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dsng7z\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dorbjv\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dli3k6\n",
      "No of posts 21\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gis3xu\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gg651b\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_geuszg\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gd4jpo\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gad0ah\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g7moca\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g469ow\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g1vppx\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fz4oke\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fw43h8\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ftk2ap\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_frj7h1\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fnrsvr\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fl4rnw\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fi20py\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fg471r\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fdquhb\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fcanxx\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f9fqm1\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f6znd5\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f4rwrv\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f1o83o\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_eycuyz\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_euwtm6\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ese859\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_eo6sf5\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_elb9sv\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ehiufb\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ed74xx\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ebsba1\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e9jcd0\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e6lxnk\n",
      "No of posts 25\n",
      "5\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_e2fskv\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dzutvv\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dw9or8\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dsng7z\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dorbjv\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_dli3k6\n",
      "No of posts 21\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gis3xu\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gg651b\n",
      "No of posts 25\n",
      "10\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_geuszg\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gd4jpo\n",
      "No of posts 25\n",
      "9\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_gad0ah\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g7moca\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g469ow\n",
      "No of posts 25\n",
      "7\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_g1vppx\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fz4oke\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fw43h8\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_ftk2ap\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_frj7h1\n",
      "No of posts 25\n",
      "4\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fnrsvr\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fl4rnw\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fi20py\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fg471r\n",
      "No of posts 25\n",
      "3\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fdquhb\n",
      "No of posts 25\n",
      "8\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_fcanxx\n",
      "No of posts 25\n",
      "2\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f9fqm1\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f6znd5\n",
      "No of posts 25\n",
      "6\n",
      "https://www.reddit.com/r/bigdata.json?after=t3_f4rwrv\n",
      "No of posts 25\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Define function for data scraping\n",
    "\n",
    "# def data_scrape(url, num):\n",
    "    \n",
    "# Get posts as list of dictionaries, each containing data on one post\n",
    "posts = []\n",
    "\n",
    "for url in urls:\n",
    "    after = None\n",
    "\n",
    "    for a in range(100):\n",
    "        if after == None:\n",
    "            current_url = url\n",
    "        else:\n",
    "            current_url = url + '?after=' + after\n",
    "        print(current_url)\n",
    "        res = requests.get(current_url, headers={'User-agent': 'Learn Python Bot 1.0'})\n",
    "    \n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "    \n",
    "        df_posts = pd.DataFrame(posts)\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        print (\"No of posts \" + str(len(current_posts)))\n",
    "        posts.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "    \n",
    "        pd.DataFrame(posts).to_csv('../datasets/bigdata.csv', index=False)\n",
    "    \n",
    "        # generate a random sleep duration to look more 'natural'\n",
    "        sleep_duration = random.randint(2,10)\n",
    "        print(sleep_duration)\n",
    "        time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Import Data and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>poll_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_xf2t5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Spark Partitions</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>35554</td>\n",
       "      <td>1.589729e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...</td>\n",
       "      <td>t2_6g6ggfmr</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Hadoop Distributed File System - A comprehensive guide</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>35554</td>\n",
       "      <td>1.589701e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'grt1zi433az41': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 127, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_ku4l5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Laughing at Big Data – eBook – Great new insight into realities of IT</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>35554</td>\n",
       "      <td>1.589613e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_ku4l5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Why I called bullshit on the data lakehouse nonsense</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>35554</td>\n",
       "      <td>1.589641e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...</td>\n",
       "      <td>t2_150ojy</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>What Is Data Warehouse As a Service and Why Would You Need It</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>35554</td>\n",
       "      <td>1.589615e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approved_at_utc subreddit  \\\n",
       "0              NaN   bigdata   \n",
       "1              NaN   bigdata   \n",
       "2              NaN   bigdata   \n",
       "3              NaN   bigdata   \n",
       "4              NaN   bigdata   \n",
       "\n",
       "                                                                                              selftext  \\\n",
       "0                                                                                                  NaN   \n",
       "1  From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...   \n",
       "2                                                                                                  NaN   \n",
       "3                                                                                                  NaN   \n",
       "4  One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...   \n",
       "\n",
       "  author_fullname  saved  mod_reason_title  gilded  clicked  \\\n",
       "0        t2_xf2t5  False               NaN       0    False   \n",
       "1     t2_6g6ggfmr  False               NaN       0    False   \n",
       "2        t2_ku4l5  False               NaN       0    False   \n",
       "3        t2_ku4l5  False               NaN       0    False   \n",
       "4       t2_150ojy  False               NaN       0    False   \n",
       "\n",
       "                                                                   title  \\\n",
       "0                                                       Spark Partitions   \n",
       "1                 Hadoop Distributed File System - A comprehensive guide   \n",
       "2  Laughing at Big Data – eBook – Great new insight into realities of IT   \n",
       "3                   Why I called bullshit on the data lakehouse nonsense   \n",
       "4          What Is Data Warehouse As a Service and Why Would You Need It   \n",
       "\n",
       "  link_flair_richtext  ... subreddit_subscribers   created_utc  \\\n",
       "0                  []  ...                 35554  1.589729e+09   \n",
       "1                  []  ...                 35554  1.589701e+09   \n",
       "2                  []  ...                 35554  1.589613e+09   \n",
       "3                  []  ...                 35554  1.589641e+09   \n",
       "4                  []  ...                 35554  1.589615e+09   \n",
       "\n",
       "   num_crossposts  media  is_video  \\\n",
       "0               0    NaN     False   \n",
       "1               0    NaN     False   \n",
       "2               0    NaN     False   \n",
       "3               0    NaN     False   \n",
       "4               0    NaN     False   \n",
       "\n",
       "                                                                                        media_metadata  \\\n",
       "0                                                                                                  NaN   \n",
       "1  {'grt1zi433az41': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 127, '...   \n",
       "2                                                                                                  NaN   \n",
       "3                                                                                                  NaN   \n",
       "4                                                                                                  NaN   \n",
       "\n",
       "  crosspost_parent_list  crosspost_parent author_cakeday  poll_data  \n",
       "0                   NaN               NaN            NaN        NaN  \n",
       "1                   NaN               NaN            NaN        NaN  \n",
       "2                   NaN               NaN            NaN        NaN  \n",
       "3                   NaN               NaN            NaN        NaN  \n",
       "4                   NaN               NaN            NaN        NaN  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df = pd.read_csv('../datasets/bigdata.csv')\n",
    "bd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 106)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df = bd_df[['name','title','selftext','subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2492, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_glhbet</td>\n",
       "      <td>Spark Partitions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_glbdff</td>\n",
       "      <td>Hadoop Distributed File System - A comprehensive guide</td>\n",
       "      <td>From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_gkqdor</td>\n",
       "      <td>Laughing at Big Data – eBook – Great new insight into realities of IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_gkw1lm</td>\n",
       "      <td>Why I called bullshit on the data lakehouse nonsense</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_gkqu9a</td>\n",
       "      <td>What Is Data Warehouse As a Service and Why Would You Need It</td>\n",
       "      <td>One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...</td>\n",
       "      <td>bigdata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  \\\n",
       "0  t3_glhbet   \n",
       "1  t3_glbdff   \n",
       "2  t3_gkqdor   \n",
       "3  t3_gkw1lm   \n",
       "4  t3_gkqu9a   \n",
       "\n",
       "                                                                   title  \\\n",
       "0                                                       Spark Partitions   \n",
       "1                 Hadoop Distributed File System - A comprehensive guide   \n",
       "2  Laughing at Big Data – eBook – Great new insight into realities of IT   \n",
       "3                   Why I called bullshit on the data lakehouse nonsense   \n",
       "4          What Is Data Warehouse As a Service and Why Would You Need It   \n",
       "\n",
       "                                                                                              selftext  \\\n",
       "0                                                                                                  NaN   \n",
       "1  From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...   \n",
       "2                                                                                                  NaN   \n",
       "3                                                                                                  NaN   \n",
       "4  One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...   \n",
       "\n",
       "  subreddit  \n",
       "0   bigdata  \n",
       "1   bigdata  \n",
       "2   bigdata  \n",
       "3   bigdata  \n",
       "4   bigdata  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df.drop_duplicates(subset='name',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name           0\n",
       "title          0\n",
       "selftext     623\n",
       "subreddit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not all post have selftext, but the subreddit are complete and unique, so we going to reaplce the NaN values with empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df['selftext'].fillna(value='',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "title        0\n",
       "selftext     0\n",
       "subreddit    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the null value again\n",
    "bd_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df['title_text'] = bd_df['title'] + \" \" + bd_df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                        Spark Partitions \n",
       "1      Hadoop Distributed File System - A comprehensive guide From a computing perspective, there are e...\n",
       "2                                   Laughing at Big Data – eBook – Great new insight into realities of IT \n",
       "3                                                    Why I called bullshit on the data lakehouse nonsense \n",
       "4      What Is Data Warehouse As a Service and Why Would You Need It One of the big headaches of a trad...\n",
       "                                                      ...                                                 \n",
       "966                       Big Data in Retail Industry [Case Studies] - Take your Business to Next Level!! \n",
       "967                                                            A Brief Introduction Of Big Data Framework \n",
       "968                                                                         Simplifying the data pipeline \n",
       "969                                      Mainframe to Big Data - Why you should switch your career today? \n",
       "970    Ideas for Big Data presentation I don't know if this is the right place to ask about this, but I...\n",
       "Name: title_text, Length: 971, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df['title_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_glhbet</td>\n",
       "      <td>Spark Partitions</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>Spark Partitions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_glbdff</td>\n",
       "      <td>Hadoop Distributed File System - A comprehensive guide</td>\n",
       "      <td>From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>Hadoop Distributed File System - A comprehensive guide From a computing perspective, there are e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_gkqdor</td>\n",
       "      <td>Laughing at Big Data – eBook – Great new insight into realities of IT</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>Laughing at Big Data – eBook – Great new insight into realities of IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_gkw1lm</td>\n",
       "      <td>Why I called bullshit on the data lakehouse nonsense</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>Why I called bullshit on the data lakehouse nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_gkqu9a</td>\n",
       "      <td>What Is Data Warehouse As a Service and Why Would You Need It</td>\n",
       "      <td>One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>What Is Data Warehouse As a Service and Why Would You Need It One of the big headaches of a trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  \\\n",
       "0  t3_glhbet   \n",
       "1  t3_glbdff   \n",
       "2  t3_gkqdor   \n",
       "3  t3_gkw1lm   \n",
       "4  t3_gkqu9a   \n",
       "\n",
       "                                                                   title  \\\n",
       "0                                                       Spark Partitions   \n",
       "1                 Hadoop Distributed File System - A comprehensive guide   \n",
       "2  Laughing at Big Data – eBook – Great new insight into realities of IT   \n",
       "3                   Why I called bullshit on the data lakehouse nonsense   \n",
       "4          What Is Data Warehouse As a Service and Why Would You Need It   \n",
       "\n",
       "                                                                                              selftext  \\\n",
       "0                                                                                                        \n",
       "1  From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...   \n",
       "2                                                                                                        \n",
       "3                                                                                                        \n",
       "4  One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...   \n",
       "\n",
       "  subreddit  \\\n",
       "0   bigdata   \n",
       "1   bigdata   \n",
       "2   bigdata   \n",
       "3   bigdata   \n",
       "4   bigdata   \n",
       "\n",
       "                                                                                            title_text  \n",
       "0                                                                                    Spark Partitions   \n",
       "1  Hadoop Distributed File System - A comprehensive guide From a computing perspective, there are e...  \n",
       "2                               Laughing at Big Data – eBook – Great new insight into realities of IT   \n",
       "3                                                Why I called bullshit on the data lakehouse nonsense   \n",
       "4  What Is Data Warehouse As a Service and Why Would You Need It One of the big headaches of a trad...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the &amp, &gt, %lt and XML character entity reference back to &, > and <\n",
    "bd_df['title_text'] = bd_df['title_text'].apply(unescape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the http, www into blank\n",
    "bd_df['title_text'] = bd_df['title_text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)#removing links\n",
    "    text = text.lower()  #making eveything lower case\n",
    "    text = re.sub('\\[.*?()\\]',' ',text) #removing some punctuation\n",
    "    text = re.sub('[%s]'%re.escape(string.punctuation),'',text)  #removing more punctuation\n",
    "    text = re.sub('\\w*d\\w*',' ',text) #removing words with numbers in them\n",
    "    text = re.sub('\\d',' ',text) #removing numbers\n",
    "    text = re.sub('\\n',' ',text) #removing newlines\n",
    "    return text\n",
    "cleaner= lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df['title_text'] = bd_df['title_text'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_glhbet</td>\n",
       "      <td>Spark Partitions</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>spark partitions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_glbdff</td>\n",
       "      <td>Hadoop Distributed File System - A comprehensive guide</td>\n",
       "      <td>From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>file system  a comprehensive   from a computing perspective there are essentially   types of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_gkqdor</td>\n",
       "      <td>Laughing at Big Data – eBook – Great new insight into realities of IT</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>laughing at big   – ebook – great new insight into realities of it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_gkw1lm</td>\n",
       "      <td>Why I called bullshit on the data lakehouse nonsense</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>why i   bullshit on the   lakehouse nonsense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_gkqu9a</td>\n",
       "      <td>What Is Data Warehouse As a Service and Why Would You Need It</td>\n",
       "      <td>One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>what is   warehouse as a service   why   you   it one of the big   of a     warehouse is its    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3_gkeozm</td>\n",
       "      <td>Big Data: Its Impact and Significance</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>big   its impact   significance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3_gkdqs3</td>\n",
       "      <td>Computational social science #bigdatalearning #learning #socialnetworksanalysis #onlinecourse</td>\n",
       "      <td>Hi from the University of California\\n\\nInterested in learning more about Computational Social S...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>computational social science   learning socialnetworksanalysis onlinecourse hi from the universi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t3_gkakk1</td>\n",
       "      <td>Webinar on How To Choose the Right Data Science Program For Your Career</td>\n",
       "      <td></td>\n",
       "      <td>bigdata</td>\n",
       "      <td>webinar on how to choose the right   science program for your career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3_gk59h2</td>\n",
       "      <td>Role of Web Scraping in the E-commerce Industry</td>\n",
       "      <td>[E commerce web scraping](https://www.loginworks.com/ecommerce-web-scraping) provides a bird’s e...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>role of web scraping in the ecommerce       a  ’s eye view of pricing   market   prevailing patt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3_gk2oof</td>\n",
       "      <td>Doing redesign of Statistics without Borders non-profit organization</td>\n",
       "      <td>Hi everyone! I’m a UX designer student and my team is working on a redesign of a non-profit orga...</td>\n",
       "      <td>bigdata</td>\n",
       "      <td>of statistics without   nonprofit organization hi everyone i’m a ux       my team is working...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  \\\n",
       "0  t3_glhbet   \n",
       "1  t3_glbdff   \n",
       "2  t3_gkqdor   \n",
       "3  t3_gkw1lm   \n",
       "4  t3_gkqu9a   \n",
       "5  t3_gkeozm   \n",
       "6  t3_gkdqs3   \n",
       "7  t3_gkakk1   \n",
       "8  t3_gk59h2   \n",
       "9  t3_gk2oof   \n",
       "\n",
       "                                                                                           title  \\\n",
       "0                                                                               Spark Partitions   \n",
       "1                                         Hadoop Distributed File System - A comprehensive guide   \n",
       "2                          Laughing at Big Data – eBook – Great new insight into realities of IT   \n",
       "3                                           Why I called bullshit on the data lakehouse nonsense   \n",
       "4                                  What Is Data Warehouse As a Service and Why Would You Need It   \n",
       "5                                                          Big Data: Its Impact and Significance   \n",
       "6  Computational social science #bigdatalearning #learning #socialnetworksanalysis #onlinecourse   \n",
       "7                        Webinar on How To Choose the Right Data Science Program For Your Career   \n",
       "8                                                Role of Web Scraping in the E-commerce Industry   \n",
       "9                           Doing redesign of Statistics without Borders non-profit organization   \n",
       "\n",
       "                                                                                              selftext  \\\n",
       "0                                                                                                        \n",
       "1  From a computing perspective, there are essentially 2 types of scaling — vertical and horizontal...   \n",
       "2                                                                                                        \n",
       "3                                                                                                        \n",
       "4  One of the big headaches of a traditional data warehouse is its hardware and software infrastruc...   \n",
       "5                                                                                                        \n",
       "6  Hi from the University of California\\n\\nInterested in learning more about Computational Social S...   \n",
       "7                                                                                                        \n",
       "8  [E commerce web scraping](https://www.loginworks.com/ecommerce-web-scraping) provides a bird’s e...   \n",
       "9  Hi everyone! I’m a UX designer student and my team is working on a redesign of a non-profit orga...   \n",
       "\n",
       "  subreddit  \\\n",
       "0   bigdata   \n",
       "1   bigdata   \n",
       "2   bigdata   \n",
       "3   bigdata   \n",
       "4   bigdata   \n",
       "5   bigdata   \n",
       "6   bigdata   \n",
       "7   bigdata   \n",
       "8   bigdata   \n",
       "9   bigdata   \n",
       "\n",
       "                                                                                            title_text  \n",
       "0                                                                                    spark partitions   \n",
       "1      file system  a comprehensive   from a computing perspective there are essentially   types of...  \n",
       "2                                  laughing at big   – ebook – great new insight into realities of it   \n",
       "3                                                        why i   bullshit on the   lakehouse nonsense   \n",
       "4  what is   warehouse as a service   why   you   it one of the big   of a     warehouse is its    ...  \n",
       "5                                                                     big   its impact   significance   \n",
       "6  computational social science   learning socialnetworksanalysis onlinecourse hi from the universi...  \n",
       "7                                webinar on how to choose the right   science program for your career   \n",
       "8  role of web scraping in the ecommerce       a  ’s eye view of pricing   market   prevailing patt...  \n",
       "9      of statistics without   nonprofit organization hi everyone i’m a ux       my team is working...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data Frame Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_df.to_csv('../datasets/BigData_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web scraping and data cleaning process had created a DataFrame table which containing titles,post and combined values(title_text) and save to a csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
